{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hl100\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import flwr as fl\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from numpy import newaxis\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from scipy.stats import chi2\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, AutoModel\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Function\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from centralized import DomainAdaptationModel,ReviewDataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DomainAdaptationClient(fl.client.NumPyClient):\n",
    "    def __init__(self, model, train_loader, test_loader, device):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.device = device\n",
    "\n",
    "    # def get_parameters(self):\n",
    "    #     return [val.cpu().numpy() for val in self.model.state_dict().values()]\n",
    "\n",
    "    def set_parameters(self, parameters):\n",
    "        state_dict = {k: torch.tensor(v) for k, v in zip(self.model.state_dict().keys(), parameters)}\n",
    "        self.model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        print(\"Starting Trainning...\")\n",
    "        self.model.train()\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)\n",
    "        for epoch in range(1):  # Perform a single epoch of training\n",
    "            for batch in self.train_loader:\n",
    "                input_ids, attention_mask, token_type_ids, labels = [x.to(self.device) for x in batch]\n",
    "                print(\"input_ids shape:\", input_ids.shape)\n",
    "                print(\"attention_mask shape:\", attention_mask.shape)\n",
    "                if token_type_ids is not None:\n",
    "                    print(\"token_type_ids shape:\", token_type_ids.shape)\n",
    "                inputs = {\n",
    "                        \"input_ids\": input_ids.squeeze(axis=1),\n",
    "                        \"attention_mask\": attention_mask.squeeze(axis=1),\n",
    "                        \"token_type_ids\" : token_type_ids.squeeze(axis=1),\n",
    "                        \"labels\" : labels\n",
    "                    }\n",
    "                for k, v in inputs.items():\n",
    "                    inputs[k] = v.to(device)\n",
    "                # sentiment_pred, domain_pred = self.model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "                sentiment_pred, domain_pred = self.model(**inputs)\n",
    "                loss = self.compute_loss(sentiment_pred, domain_pred, labels)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        return self.get_parameters(), len(self.train_loader.dataset), {}\n",
    "\n",
    "    def compute_loss(self, sentiment_pred, domain_pred, labels):\n",
    "        sentiment_loss = torch.nn.CrossEntropyLoss()(sentiment_pred, labels)\n",
    "        domain_loss = torch.nn.CrossEntropyLoss()(domain_pred, labels)  # Assuming domain labels are in labels\n",
    "        return sentiment_loss + domain_loss\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        self.model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        print(\"Starting evaluation...\")\n",
    "        total_batches = len(self.test_loader)\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch in enumerate(self.test_loader):\n",
    "                input_ids, attention_mask, token_type_ids, labels = [x.to(self.device) for x in batch]\n",
    "                inputs = {\n",
    "                        \"input_ids\": input_ids.squeeze(axis=1),\n",
    "                        \"attention_mask\": attention_mask.squeeze(axis=1),\n",
    "                        \"token_type_ids\" : token_type_ids.squeeze(axis=1),\n",
    "                        \"labels\" : labels\n",
    "                    }\n",
    "                for k, v in inputs.items():\n",
    "                    inputs[k] = v.to(device)\n",
    "                # sentiment_pred, domain_pred = self.model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "                sentiment_pred, domain_pred = self.model(**inputs)\n",
    "                _, predicted = torch.max(sentiment_pred, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                print(f\"Batch {batch_idx + 1}/{total_batches} completed: {(batch_idx + 1) / total_batches * 100:.2f}%\")\n",
    "        accuracy = correct / total\n",
    "        return float(accuracy), len(self.test_loader.dataset),{\"accuracy\": accuracy}\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:9: SyntaxWarning: invalid escape sequence '\\H'\n",
      "<>:9: SyntaxWarning: invalid escape sequence '\\H'\n",
      "C:\\Users\\hl100\\AppData\\Local\\Temp\\ipykernel_6416\\2090366637.py:9: SyntaxWarning: invalid escape sequence '\\H'\n",
      "  df_full = pd.read_csv('D:\\Hoc\\SecBert\\SecBERT\\multilabel-train\\dataset_capec.csv')\n",
      "c:\\Users\\hl100\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "000 - Normal                              30\n",
      "126 - Path Traversal                      30\n",
      "66 - SQL Injection                        30\n",
      "272 - Protocol Manipulation               30\n",
      "310 - Scanning for Vulnerable Software    30\n",
      "242 - Code Injection                      30\n",
      "153 - Input Data Manipulation             30\n",
      "194 - Fake the Source of Data             30\n",
      "34 - HTTP Response Splitting              30\n",
      "Name: count, dtype: int64\n",
      "540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hl100\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Model\n",
    "model = DomainAdaptationModel()\n",
    "tokenizer = AutoTokenizer.from_pretrained('jackaduma/SecBERT')\n",
    "\n",
    "model.to(device)\n",
    "# state_dict_path = 'C:/Users/hl100/Downloads/' + 'size250k_1epoch_1_model.bin'\n",
    "# model.load_state_dict(torch.load(state_dict_path, map_location=device))\n",
    "#Data\n",
    "df_full = pd.read_csv('D:\\Hoc\\SecBert\\SecBERT\\multilabel-train\\dataset_capec.csv')\n",
    "# df_full = pd.read_csv('E:\\Work_DatPT\\Study\\Master\\SecBERT\\dataset_capec.csv')\n",
    "df_full['text'] = df_full['text'].str.replace('/',' ')\n",
    "df_train = df_full.groupby('label').head(30)\n",
    "# df_train = df_full\n",
    "df_train = df_train.dropna(subset=['label'])\n",
    "label_counts = df_train['label'].value_counts()\n",
    "print(label_counts)\n",
    "print(df_train.size)\n",
    "\n",
    "\n",
    "train_df, test_df = train_test_split(df_train, test_size=0.2, random_state=42)\n",
    "train_texts = train_df['text'].values\n",
    "train_labels = train_df['label'].values\n",
    "test_texts = test_df['text'].values\n",
    "test_labels = test_df['label'].values\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df_train['text'], df_train['label'],test_size=0.3, stratify=df_train['label'], shuffle = True)\n",
    "df_train = pd.concat([X_train, Y_train], axis=1)\n",
    "df_test = pd.concat([X_test, Y_test], axis=1)\n",
    "\n",
    "# Tokenize the loaded texts for training and testing\n",
    "train_dataset = ReviewDataset(df_train)\n",
    "test_dataset = ReviewDataset(df_test)\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers = 2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers = 2) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. \n",
      "\tInstead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: \n",
      "\tflwr.client.start_client(\n",
      "\t\tserver_address='<IP>:<PORT>',\n",
      "\t\tclient=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object\n",
      "\t)\n",
      "\tUsing `start_numpy_client()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      Received: evaluate message 861785b4-b6da-472b-943e-fc5c41f3c07f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation...\n",
      "input_ids shape: torch.Size([8, 1, 512])\n",
      "attention_mask shape: torch.Size([8, 1, 512])\n",
      "token_type_ids shape: torch.Size([8, 1, 512])\n",
      "input_ids shape: torch.Size([8, 1, 512])\n",
      "attention_mask shape: torch.Size([8, 1, 512])\n",
      "token_type_ids shape: torch.Size([8, 1, 512])\n",
      "input_ids shape: torch.Size([8, 1, 512])\n",
      "attention_mask shape: torch.Size([8, 1, 512])\n",
      "token_type_ids shape: torch.Size([8, 1, 512])\n",
      "input_ids shape: torch.Size([8, 1, 512])\n",
      "attention_mask shape: torch.Size([8, 1, 512])\n",
      "token_type_ids shape: torch.Size([8, 1, 512])\n",
      "input_ids shape: torch.Size([8, 1, 512])\n",
      "attention_mask shape: torch.Size([8, 1, 512])\n",
      "token_type_ids shape: torch.Size([8, 1, 512])\n",
      "input_ids shape: torch.Size([8, 1, 512])\n",
      "attention_mask shape: torch.Size([8, 1, 512])\n",
      "token_type_ids shape: torch.Size([8, 1, 512])\n",
      "input_ids shape: torch.Size([8, 1, 512])\n",
      "attention_mask shape: torch.Size([8, 1, 512])\n",
      "token_type_ids shape: torch.Size([8, 1, 512])\n",
      "input_ids shape: torch.Size([8, 1, 512])\n",
      "attention_mask shape: torch.Size([8, 1, 512])\n",
      "token_type_ids shape: torch.Size([8, 1, 512])\n",
      "input_ids shape: torch.Size([8, 1, 512])\n",
      "attention_mask shape: torch.Size([8, 1, 512])\n",
      "token_type_ids shape: torch.Size([8, 1, 512])\n",
      "input_ids shape: torch.Size([8, 1, 512])\n",
      "attention_mask shape: torch.Size([8, 1, 512])\n",
      "token_type_ids shape: torch.Size([8, 1, 512])\n",
      "input_ids shape: torch.Size([1, 1, 512])\n",
      "attention_mask shape: torch.Size([1, 1, 512])\n",
      "token_type_ids shape: torch.Size([1, 1, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Sent reply\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      Received: train message 7e04cf37-15ca-4da1-afd1-82a8ff08b087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Trainning...\n",
      "input_ids shape: torch.Size([8, 1, 512])\n",
      "attention_mask shape: torch.Size([8, 1, 512])\n",
      "token_type_ids shape: torch.Size([8, 1, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[91mERROR \u001b[0m:     Client raised an exception.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\hl100\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\flwr\\client\\app.py\", line 526, in start_client_internal\n",
      "    reply_message = client_app(message=message, context=context)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\hl100\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\flwr\\client\\client_app.py\", line 143, in __call__\n",
      "    return self._call(message, context)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\hl100\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\flwr\\client\\client_app.py\", line 126, in ffn\n",
      "    out_message = handle_legacy_message_from_msgtype(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\hl100\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\flwr\\client\\message_handler\\message_handler.py\", line 129, in handle_legacy_message_from_msgtype\n",
      "    fit_res = maybe_call_fit(\n",
      "              ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\hl100\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\flwr\\client\\client.py\", line 255, in maybe_call_fit\n",
      "    return client.fit(fit_ins)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\hl100\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\flwr\\client\\numpy_client.py\", line 259, in _fit\n",
      "    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\hl100\\AppData\\Local\\Temp\\ipykernel_6416\\2847963276.py\", line 39, in fit\n",
      "    loss.backward()\n",
      "  File \"c:\\Users\\hl100\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_tensor.py\", line 521, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"c:\\Users\\hl100\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\__init__.py\", line 282, in backward\n",
      "    grad_tensors_ = _make_grads(tensors, grad_tensors_, is_grads_batched=False)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\hl100\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\__init__.py\", line 161, in _make_grads\n",
      "    torch.ones_like(out, memory_format=torch.preserve_format)\n",
      "RuntimeError: CUDA error: device-side assert triggered\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Simulate clients\u001b[39;00m\n\u001b[0;32m      2\u001b[0m client \u001b[38;5;241m=\u001b[39m DomainAdaptationClient(model, train_loader, test_loader, device)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mfl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_numpy_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlocalhost:8088\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hl100\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\flwr\\client\\app.py:683\u001b[0m, in \u001b[0;36mstart_numpy_client\u001b[1;34m(server_address, client, grpc_max_message_length, root_certificates, insecure, transport)\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[38;5;66;03m# Calling this function is deprecated. A warning is thrown.\u001b[39;00m\n\u001b[0;32m    679\u001b[0m \u001b[38;5;66;03m# We first need to convert the supplied client to `Client.`\u001b[39;00m\n\u001b[0;32m    681\u001b[0m wrp_client \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mto_client()\n\u001b[1;32m--> 683\u001b[0m \u001b[43mstart_client\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrp_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrpc_max_message_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrpc_max_message_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43mroot_certificates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroot_certificates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43minsecure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minsecure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hl100\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\flwr\\client\\app.py:175\u001b[0m, in \u001b[0;36mstart_client\u001b[1;34m(server_address, client_fn, client, grpc_max_message_length, root_certificates, insecure, transport, authentication_keys, max_retries, max_wait_time)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Start a Flower client node which connects to a Flower server.\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \n\u001b[0;32m    105\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;124;03m>>> )\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    174\u001b[0m event(EventType\u001b[38;5;241m.\u001b[39mSTART_CLIENT_ENTER)\n\u001b[1;32m--> 175\u001b[0m \u001b[43mstart_client_internal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnode_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_client_app_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrpc_max_message_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrpc_max_message_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mroot_certificates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroot_certificates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43minsecure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minsecure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauthentication_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauthentication_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_wait_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_wait_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m event(EventType\u001b[38;5;241m.\u001b[39mSTART_CLIENT_LEAVE)\n",
      "File \u001b[1;32mc:\\Users\\hl100\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\flwr\\client\\app.py:533\u001b[0m, in \u001b[0;36mstart_client_internal\u001b[1;34m(server_address, node_config, load_client_app_fn, client_fn, client, grpc_max_message_length, root_certificates, insecure, transport, authentication_keys, max_retries, max_wait_time, flwr_path, isolation, supernode_address)\u001b[0m\n\u001b[0;32m    531\u001b[0m     log(ERROR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClient raised an exception.\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39mex)\n\u001b[0;32m    532\u001b[0m     \u001b[38;5;66;03m# Raise exception, crash process\u001b[39;00m\n\u001b[1;32m--> 533\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex\n\u001b[0;32m    535\u001b[0m \u001b[38;5;66;03m# Don't update/change NodeState\u001b[39;00m\n\u001b[0;32m    537\u001b[0m e_code \u001b[38;5;241m=\u001b[39m ErrorCode\u001b[38;5;241m.\u001b[39mCLIENT_APP_RAISED_EXCEPTION\n",
      "File \u001b[1;32mc:\\Users\\hl100\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\flwr\\client\\app.py:526\u001b[0m, in \u001b[0;36mstart_client_internal\u001b[1;34m(server_address, node_config, load_client_app_fn, client_fn, client, grpc_max_message_length, root_certificates, insecure, transport, authentication_keys, max_retries, max_wait_time, flwr_path, isolation, supernode_address)\u001b[0m\n\u001b[0;32m    521\u001b[0m         client_app: ClientApp \u001b[38;5;241m=\u001b[39m load_client_app_fn(\n\u001b[0;32m    522\u001b[0m             fab_id, fab_version\n\u001b[0;32m    523\u001b[0m         )\n\u001b[0;32m    525\u001b[0m         \u001b[38;5;66;03m# Execute ClientApp\u001b[39;00m\n\u001b[1;32m--> 526\u001b[0m         reply_message \u001b[38;5;241m=\u001b[39m \u001b[43mclient_app\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:  \u001b[38;5;66;03m# pylint: disable=broad-exception-caught\u001b[39;00m\n\u001b[0;32m    528\u001b[0m \n\u001b[0;32m    529\u001b[0m     \u001b[38;5;66;03m# Legacy grpc-bidi\u001b[39;00m\n\u001b[0;32m    530\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m transport \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrpc-bidi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m]:\n",
      "File \u001b[1;32mc:\\Users\\hl100\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\flwr\\client\\client_app.py:143\u001b[0m, in \u001b[0;36mClientApp.__call__\u001b[1;34m(self, message, context)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;66;03m# Execute message using `client_fn`\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call:\n\u001b[1;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;66;03m# Execute message using a new\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mmessage_type \u001b[38;5;241m==\u001b[39m MessageType\u001b[38;5;241m.\u001b[39mTRAIN:\n",
      "File \u001b[1;32mc:\\Users\\hl100\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\flwr\\client\\client_app.py:126\u001b[0m, in \u001b[0;36mClientApp.__init__.<locals>.ffn\u001b[1;34m(message, context)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mffn\u001b[39m(\n\u001b[0;32m    123\u001b[0m     message: Message,\n\u001b[0;32m    124\u001b[0m     context: Context,\n\u001b[0;32m    125\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Message:  \u001b[38;5;66;03m# pylint: disable=invalid-name\u001b[39;00m\n\u001b[1;32m--> 126\u001b[0m     out_message \u001b[38;5;241m=\u001b[39m \u001b[43mhandle_legacy_message_from_msgtype\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out_message\n",
      "File \u001b[1;32mc:\\Users\\hl100\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\flwr\\client\\message_handler\\message_handler.py:129\u001b[0m, in \u001b[0;36mhandle_legacy_message_from_msgtype\u001b[1;34m(client_fn, message, context)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m# Handle FitIns\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m message_type \u001b[38;5;241m==\u001b[39m MessageType\u001b[38;5;241m.\u001b[39mTRAIN:\n\u001b[1;32m--> 129\u001b[0m     fit_res \u001b[38;5;241m=\u001b[39m \u001b[43mmaybe_call_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_ins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecordset_to_fitins\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m     out_recordset \u001b[38;5;241m=\u001b[39m fitres_to_recordset(fit_res, keep_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m# Handle EvaluateIns\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hl100\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\flwr\\client\\client.py:255\u001b[0m, in \u001b[0;36mmaybe_call_fit\u001b[1;34m(client, fit_ins)\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m FitRes(\n\u001b[0;32m    248\u001b[0m         status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[0;32m    249\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mParameters(tensor_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, tensors\u001b[38;5;241m=\u001b[39m[]),\n\u001b[0;32m    250\u001b[0m         num_examples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    251\u001b[0m         metrics\u001b[38;5;241m=\u001b[39m{},\n\u001b[0;32m    252\u001b[0m     )\n\u001b[0;32m    254\u001b[0m \u001b[38;5;66;03m# If the client implements `fit`, call it\u001b[39;00m\n\u001b[1;32m--> 255\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfit_ins\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hl100\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\flwr\\client\\numpy_client.py:259\u001b[0m, in \u001b[0;36m_fit\u001b[1;34m(self, ins)\u001b[0m\n\u001b[0;32m    256\u001b[0m parameters: NDArrays \u001b[38;5;241m=\u001b[39m parameters_to_ndarrays(ins\u001b[38;5;241m.\u001b[39mparameters)\n\u001b[0;32m    258\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[1;32m--> 259\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28mlen\u001b[39m(results) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m)\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m    264\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[\u001b[38;5;241m2\u001b[39m], \u001b[38;5;28mdict\u001b[39m)\n\u001b[0;32m    265\u001b[0m ):\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(EXCEPTION_MESSAGE_WRONG_RETURN_TYPE_FIT)\n",
      "Cell \u001b[1;32mIn[15], line 39\u001b[0m, in \u001b[0;36mDomainAdaptationClient.fit\u001b[1;34m(self, parameters, config)\u001b[0m\n\u001b[0;32m     37\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(sentiment_pred, domain_pred, labels)\n\u001b[0;32m     38\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 39\u001b[0m         \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_parameters(), \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader\u001b[38;5;241m.\u001b[39mdataset), {}\n",
      "File \u001b[1;32mc:\\Users\\hl100\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    520\u001b[0m     )\n\u001b[1;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hl100\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\__init__.py:282\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    273\u001b[0m inputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    274\u001b[0m     (inputs,)\n\u001b[0;32m    275\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, (torch\u001b[38;5;241m.\u001b[39mTensor, graph\u001b[38;5;241m.\u001b[39mGradientEdge))\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m()\n\u001b[0;32m    279\u001b[0m )\n\u001b[0;32m    281\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m _tensor_or_tensors_to_tuple(grad_tensors, \u001b[38;5;28mlen\u001b[39m(tensors))\n\u001b[1;32m--> 282\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m \u001b[43m_make_grads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_grads_batched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n",
      "File \u001b[1;32mc:\\Users\\hl100\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\__init__.py:161\u001b[0m, in \u001b[0;36m_make_grads\u001b[1;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[0;32m    155\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    156\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad can be implicitly created only for real scalar outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    157\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    158\u001b[0m         )\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg)\n\u001b[0;32m    160\u001b[0m     new_grads\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 161\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreserve_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    162\u001b[0m     )\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    164\u001b[0m     new_grads\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# Simulate clients\n",
    "client = DomainAdaptationClient(model, train_loader, test_loader, device)\n",
    "fl.client.start_numpy_client(server_address=\"localhost:8088\", client=client)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
